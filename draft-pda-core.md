---
title: "Private Data Aggregation Protocol"
docname: draft-pda-core-latest
category: std
ipr: trust200902
area: ART
workgroup: HTTPBIS

stand_alone: yes
pi: [toc, sortrefs, symrefs, docmapping]

author:
  -
    ins: S. People
    name: Some People
    org: Somewhere
    email: over@therainbow.net

informative:

  CB17:
    title: "Prio: Private, Robust, and Scalable Computation of Aggregate Statistics"
    date: 2017-03-14
    target: "https://crypto.stanford.edu/prio/paper.pdf"
    author:
      - ins: H. Corrigan-Gibbs
      - ins: D. Boneh

  BBCp21:
    title: "Lightweight Techniques for Private Heavy Hitters"
    date: 2021-01-05
    target: "https://eprint.iacr.org/2021/017"
    author:
      -ins: D. Boneh
      -ins: E. Boyle
      -ins: H. Corrigan-Gibbs
      -ins: N. Gilboa
      -ins: Y. Ishai

--- abstract

TODO: writeme

--- middle

# Introduction

This document describes a framework for specifying protocols for
privacy-preserving data-aggregation. Each protocol is executed by a large set of
clients and a small set of servers. The servers' goal is to compute some
aggregate statistic over the clients' inputs without learning the inputs
themselves. This is made possible by distributing the computation among the
servers in such a way that, as long as at least one of them executes the
protocol honestly, no input is ever seen in the clear by any server.

## DISCLAIMER

This document is a work in progress. We have not yet settled on the design of
the protocol framework or the set of features we intend to support.

## Terminology

This section defines some terminology we will use in the remainder of this
document.

1. Aggregation function: The function computed over the users' inputs.
1. Aggregator: An endpoint that runs the input-validation protocol and
   accumulates input shares.
1. Batch size: The number of valid input shares accumulated by each aggregator
   before computing the final output.
1. Client: The endpoint from which a user sends data to be aggregated, e.g., a
   web browser.
1. Collector: The endpoint that receives the output of the aggreagtion function.
   It also specifies the parameters of the protocol.
1. False input: An input that is valid, but incorrect. For example, if the data
   being gathered is whether or not users have clicked on a particular button, a
   client could report clicks when none occurred.
1. Input: The original data emitted by a client, before any encryption or secret
   sharing scheme is applied. This may include multiple measurements.
1. Input share: one of the shares output by feeding an input into a secret
   sharing scheme. Each share is to be transmitted to one of the participating
   aggregators.
1. Input validation protocol: The protocol executed by the client and
   aggregators in order to validate the client's input without leaking its value
   to the aggregators.
1. Invalid input: An input for which the input validation protocol fails. For
   example, if the input is meant to be a  bit vectors, then `[2, 1, 0]` is
   invalid.
1. Leader: A distinguished aggregator that coordinates input validation and data
   collection.
1. Output: A reduction over the inputs, for instance a statistical aggregation,
   which is of interest to a collector. This is the output of the aggregation
   function.
1. Output share: The share of an output emitted by an aggregator. Output shares
   can be reassembled by the leader into the final output.
1. Prio v1: Mozilla's [Origin Telemetry project](https://blog.mozilla.org/security/2019/06/06/next-steps-in-privacy-preserving-telemetry-with-prio/).
1. Prio v2: Contact tracing project by Apple, Google, and ISRG.
1. Proof: A value generated by the client used by the aggregators to verify the
   client's input.
1. Proof share: A share of a proof, used by an aggregator during the
   input-validation protocol.
1. Measurement: A single value (e.g., a count) being reported by a client.
   Multiple measurements may be grouped into a single protocol input.

# Overview {#overview}

The protocol is executed by a large set of clients and a small set of servers.
We call the servers the *aggregators*. Each client's input to the protocol is a
set of measurements (e.g., counts of some user behavior). Given the input set
of measurements `x_1, ..., x_n` held by `n` users, the goal of a
*private aggregation (PA) protocol* is to compute `y = F(x_1, ..., x_n)` for
some aggregation function `F` while revealing nothing else about the
measurements.

## Private aggregation via secret sharing

The main cryptographic tool used for achieving this privacy goal is *additive
secret sharing*. Rather than send its input in the clear, each client splits
its measurements into a sequence of *shares* and sends a share to each of the
aggregators. Additive secret sharing has two important properties:
- It's impossible to deduce the measurement without knowing *all* of the shares.
- It allows the aggregators to compute the final output by first adding up their
  measurements shares locally, then combining the results to obtain the final
  output.

Consider an illustrative example. Suppose there are three clients and two
aggregators. Each client `i` holds a single measurement in the form of a
positive integer `x[i]`, and our goal is to compute the sum of the measurements
of all clients. In this case, the protocol input is a single measurement
consisting of a single positive integer; no additional encoding is done. Given
this input, the first client splits its measurement `x[1]` with additive
secret-sharing into a pair of integers `X[1,1]` and `X[1,2]` for which `x[1]` is
equal to `X[1,1] + X[1,2]` modulo a prime number `p`. (For convenience, we will
omit the mod `p` operator in the rest of this section.) It then uploads `X[1,1]`
to one server `X[1,2]` to the other. The second client splits its measurement
`x[2]` into `X[1,2]` and `X[2,2]`, uploads them to the servers, and so on.

Now the first aggregator is in possession of shares `X[1,1]`, `X[2,1]`, and
`X[3,1]` and the second aggregator is in possession of shares `X[2,1]`,
`X[2,2]`, and `X[2,3]`. Each aggregator computes the sum of its shares; let
`A[1]` denote the first aggregator's share of the sum and let `A[2]` denote the
second aggregator's share of the sum. In the last step, aggregators combine
their sum shares to obtain the final output `y = A[1] + A[2]`. This is correct
because modular addition is commutative. I.e.,

```
    y = A[1] + A[2]
      = (x[1,1] + x[2,1] + x[3,1]) + (x[1,2] + x[2,2] + x[3,2])
      = (x[1,1] + x[1,2]) + (x[2,1] + x[2,2]) + (x[3,1] + x[3,2])
      = x[1] + x[2] + x[3]
      = F(x[1], x[2], x[3])
```

**Prio.**
This approach can be used to privately compute any function `F` that can be
expressed as a function of the sum of the users' inputs. In Prio {{CB17}}, each
user splits its input into shares and sends each share to one of the
aggregators. The aggregators sum up their input shares. Once all the shares have
been aggregated, they combine their shares of the aggregate to get the final
output.

Not all aggregate functions can be expressed this way efficiently, however. Prio
supports only a limited set of aggregation functions, some of which we highlight
below:

- Simple statistics, like sum, mean, min, max, variance, and standard deviation;
- Histograms with fixed bin sizes (also allows estimation of quantiles, e.g.,
  the median);
- More advanced statistics, like linear regression;
- Bitwise-OR and -AND on bit strings; and
- Computation of data structures, like Bloom filters, counting Bloom filters,
  and count-min sketches, that approximately represent (multi-)sets of strings.

This variety of aggregate types is sufficient to support a wide variety of
data aggregation tasks.

**Hits.**
A common PA task that can't be solved efficiently with Prio is the
`t`-*heavy-hitters* problem {{BBCp21}}. In this setting, each user is in
possession of a single `n`-bit string, and the goal is to compute the compute
the set of strings that occur at least `t` times. One reason that Prio doesn't
apply to this problem is that the proof generated by the client would be huge.

[TODO: Provide an overview of the protocol of {{BBCp21}} and provide some
intuition about how additive secret sharing is used.]

## Validating inputs in zero knowledge

An essential task of any data collection pipeline is ensuring that the input
data is "valid". Going back to the example above, it's often useful to assert
that each measurement is in a certain range, e.g., `[0, 2^k)` for some `k`.
This straight-forward task is complicated in our setting by the fact that the
inputs are secret shared. In particular, a malicious client can corrupt the
computation by submitting random integers instead of a proper secret sharing of
a valid input.

To solve this problem, in each PA protocol, the client generates a
zero-knowledge proof of its input's validity that the aggregators use
to verify that their shares correspond to as valid input. The verification
procedure is designed to ensure that the aggregators learn nothing about the
input beyond its validity.

After encoding its measurements as an input to the PA protocol, the client
generates a *proof* of the input's validity. It then splits the proof into
shares and sends a share of both the proof and input to each aggregator. The
aggregators use their shares of the proof to decide if their input shares
correspond to a valid input.

## Collecting reports

As noted above, each client has a collection of measurements that it
wants to send. Each measurement is characterized by a set of
parameters that are centrally configured and provided to each client:

- A unique identifier (e.g., "dns-queries-mean")
- A description of how to collect the measurement (e.g., "count
  the number of DNS queries")
- The statistic to be computed over the measurement values (e.g., mean)
- The rules for what constitutes a valid value (e.g., must be between 0
  and 10000)

Once the client has collected the measurements to send, it needs to
turn them into a set of reports. Naively, each measurement would be
sent in its own report, but it is also possible to have multiple
measurements in a single report; clients need to be configured with
the mapping from measurements to reports. The set of measurements
that go into a report is referred to as the "input" to the report.
Because each report is independent, for the remainder of this document
we focus on a single report and its inputs.

[NOTE(cjpatton): This paragraph is slightly misleading. If you want to do a
range check for the measurement (this will usually be necessary, IMO) then
you'll need a few extra field elements to encode the input.]
The client uses the statistic to be computed in order to know how to
encode the measurement. For instance, if the statistic is mean, then
the measurement can be encoded directly. However, if the statistic is
standard deviation, then the client must send both `x` and `x^2`. Section
[TODO: cite to internal description of how to encode]
describes how to encode measurements for each statistic.
The client uses the validity rules to construct the zero knowledge
proof showing that the encoded measurement is valid.

## Data flow

[TODO: Rework this subsection so that all terms needed in the rest of the
document are defined.]

[TODO: Explain that the downside of using secret sharing is that the protocol
requires at least two servers to be online during the entire data aggregation
process. To ameliorate this problem, we run the protocol in parallel with
multiple pairs of aggregators.]

Each PA task in this document is divided into three sub-protocols as follows.

```
                    +------------+
                    |            |
                    |   Helper   <---------------+
                    |            |               |
                    +-----^------+               |
                          |                      |
                       2. |                   3. |
                          |                      |
+--------+  1.      +-----v------+         +-----v-----+
|        +---------->            |      3. |           |
| Client +---------->   Leader   +---------> Collector |
|        +---------->            |         |           |
+--------+          +-----^------+         +-----^-----+
                          |                      |
                       2. |                   3. |
                          |                      |
                    +-----V------+               |
                    |            |               |
                    |   Helper   <---------------+
                    |            |
                    +------------+
```

1. **Upload:** Each client assembles the measurements into an input for the given
   PA protocol. It generates a proof of its input's validity and splits the
   input and proof into two shares, one for the leader and another for a helper.
   Rather than send each share to each aggregator directly, the client encrypts
   each share under the helper's public key and sends the ciphertext to the
   leader. The client repeats this procedure for each helper specified by the
   leader.
1. **Verify:** The leader initializes the input-validation protocol by sending
   the encrypted shares to the aggregators. If the input is deemed valid, then
   each aggregator stores its input share for processing later on.
1. **Collect:** Finally, the collector interacts with the aggregators in order
   to obtain the final output of the protocol.

# PA protocols {#pa}

[TODO(cjpatton)]

# Prio {#prio}

[TODO(cjpatton): Rework this section into a specification of the protocol.]

## The input-validation protocol

Each run of the Prio protocol is parameterized by a finite field, which we will
call K, and an integer n. Each client encodes its input as a length-n vector of
element of K. The length of the vector depends on the type of data being
collected. A single field element may be sufficient for some applications,
whereas more sophisticated measurements will require larger encodings.
Each client needs to use the same encoding of inputs into vectors; if there
are multiple measurements in a single input, they will need to be in
a consistent order.

In order to share x between s servers, we split it up into s shares
{x:1}, ..., {x:s}, where {x:i} is the share held by the i-th party. We
write {x} as shorthand for the sequence {x:1}, ..., {x:s}.

Prio combines standard [linear secret
sharing](https://en.wikipedia.org/wiki/Secret_sharing#t_=_n) with a new type of
probabilistically checkable proof (PCP) system, called a fully linear PCP. The
aggregrators jointly validate the proof of correctness of the input. Before the
protocol begins, the aggregators agree on joint randomness r and designate one
of the aggregators as the leader.

The input-input validation protocol can be described in terms of three main
algorithms:

1. pf := Prove(x) denotes generation of a proof pf of the validity of input x.
   This algorithm is executed by the client.
1. {vf:i} := Query({x:i}, {pf:i}, r) denotes computation of the verification
   share {vf:i} for input share {x:i} and proof share {pf:i}. This algorithm is
   executed by each of the aggregators; input r denotes the joint randomness
   shared by all of the aggregators.
1. b := Decide({vf}, r) denotes the execution of the decision procedure on input
   shares {vf} and joint randomness r. The output b is a boolean indicating
   whether the input is deemed valid. This algorithm is run by the leader.

The values above have following types:

1. Input x is vector of length n elements of K.
1. Proof pf is a vector of length p(n) of elements of K.
1. The joint randomness r is a vector of length u(n) of elements of K.
1. Each verification share {vf:i} is a vector of length v(n) of elements of K.

Above, p(n), u(n), and v(n) are functions that we specify later.

The protocol proceeds as follows:

1. The client runs pf := Prove(x). It splits x and pf into {x} and {pf}
   respectively and sends ({x:i}, {pf:i}) to aggregator i.
1. Each aggregator i runs {vf:i} := Query({x:i}, {pf:i}, r) ands sends {vf:i} to
   the leader.
1. The leader runs b := Decide({vf}, r) and sends b to each of the aggregators.

If b=True, then each aggregator i adds its input share {x:i} into its share of the
aggregate. Once a sufficient number of inputs have been validated and
aggregated, the aggregators send their aggregate shares to the leader, who adds
them together to obtain the final result.

[[TODO: Sketch out the b=1 path.]]

**Proof generation and verification.**
[[TODO: Describe how to construct proof systems for languages recognized by
validity circuits with G-gates, a la {{?BBCp19=DOI.10.1007/978-3-030-26954-8_3}}, Theorem 4.3.]]

**Security parameters.**
[[TODO: Define completeness, soundness, and honest-verifier zero-knowledge for
fully linear PCPs and state bounds for {{BBCp19}}, Theorem 4.3. This bound will
guide the selection of the field best suited for the data type and
application.]]

**Consensus protocol.**
[[TODO: Describe how the aggregators pick the leader and the joint randomness.]]

**Key distribution.**
[[TODO: Decide how clients obtain aggregators' public keys.]]

## Changes to the input-validation protocol

**Coordinating state.**
The state of the input-validation protocol is maintained by the leader; except
for aggregation of the input shares, the other aggregators are completely
stateless. In order to achieve this:

1. The client sends all of its shares to the leader. To maintain privacy, the
   client encrypts each (input, proof) share under the public key of the share's
   recipient.
1. The leader forwards each encrypted share to its intended recipient. Each
   aggregator decrypts its input and proof share, computes its verification
   share, and sends its verification share to the aggregator as usual.
1. If b=1 in the last step, then the leader also sends along the encrypted input
   share to each aggregator so that they can decrypt and aggregate the share
   without needing to cache the input share from the previous step.

**Minimizing communication overhead.**
In most linear secret sharing schemes, the length of each share is equal to the
length of the input. Therefore, the communication overhead for the client is
O(s\*(n+p(n))). This can be reduced to O(s+n+p(n)) with the following standard
trick.

Let x be an element of K^n for some n. Suppose we split x into {x} by choosing
{x:1}, ..., {x:s-1} at random and letting {x:s} = x - ({x:1} + ... + {x:s-1}).
We could instead choose s-1 random seeds k[s-1], ..., k[s-1] for a pseudorandom
number generator PRG and let {x:i} = PRG(k[i], n) for each i. This effectively
"compresses" s-1 of the shares to O(1) space.
[[OPEN ISSUE:Move this elsewhere or something.]]]

## Primitives

This section describes the core cryptographic primitives of the system.

### Finite field arithmetic

The algorithms that comprise the input-validation protocol --- Prove, Query, and
Decide --- are constructed by generating and evaluating polynomials over a
finite field. As such, the main ingredient of Prio is an implementation of
arithmetic in a finite field suitable for the given application.

We will use a prime field. The choice of prime is influenced by the following
criteria:

1. **Field size.** How big the field needs to be depends on the type of data
   being aggregated and how many users there are. The field size also impacts
   the security level: the longer the validity circuit, the larger the field
   needs to be in order to effectively detect malicious clients. Typically the
   soundness error (i.e., the probability of an invalid input being deemed valid
   by the aggregators) will be 2n/(p-n), where n is the size of the input and p
   is the prime modulus.
1. **Fast polynomial operations.** In order to make Prio practical, it's
   important that implementations employ FFT to speed up polynomial operations.
   In particular, the prime modulus p should be chosen so that (p-1) = 2^b * s
   for large b and odd s. Then g^s is a principle, 2^b-th root of unity (i.e.,
   g^(s\*2^b) = 1), where g is the generator of the multiplicative subgroup.
   This fact allows us to quickly evaluate and interpolate polynomials at 2^a-th
   roots of unity for 1 <= a <= b.
1. **Highly composite subgroup.** Suppose that (p-1) = 2^b * s. It's best if s
   is highly composite because this minimizes the number of multiplications
   required to compute the inverse or apply Fermat's Little Theorem. (See
   [BBG+19, Section 5.2].)
1. **Code optimization.** [[TODO: What properties of the field make
   it possible to write faster implementations?]]

The table below lists parameters that meet these criteria at various levels of
security. (Note that \#1 is the field used in "Prio v2".) The "size" column
indicates the number of bits required to represent elements of the field.

| # | size | p                                      | g  | b   | s                |
|---|------|----------------------------------------|----|-----|------------------|
| 1 | 32   | 4293918721                             | 19 | 20  | 3^2 * 5 * 7 * 13 |
| 2 | 64   | 15564440312192434177                   | 5  | 59  | 3^3              |
| 3 | 80   | 779190469673491460259841               | 14 | 72  | 3 * 5 * 11       |
| 4 | 123  | 9304595970494411110326649421962412033  | 3  | 120 | 7                |
| 5 | 126  | 74769074762901517850839147140769382401 | 7  | 118 | 3^2 * 5^2        |

**Finding suitable primes.**
One way to find suitable primes is to first choose choose b, then "probe" to
find a prime of the desired size. The following SageMath script prints the
parameters of a number of (probable) primes larger than 2^b for a given b:

```
b = 116
for s in range(0,1000,1):
    B = 2^b
    p = (B*s).next_prime()
    if p-(B*s) == 1:
        bits = round(math.log2(p), 2)
        print(bits, p, GF(p).multiplicative_generator(), b, factor(s))
```

### Key encapsulation

Our instantiation of the input-validation protocol involves two additional
operations: public key encryption and cryptographically secure pseudorandom
number generation (CSPRNG). The combination of these primitives that we use here
allows us to make an additional simplification. We assume that clients
communicate with the leader over a confidential and authenticated channel, such
as TLS. As a result, we only need to encrypt CSPRNG seeds, which requires only a
key-encapsulation mechanism (KEM) rather than full-blown encryption.

A KEM is comprised of two algorithms:

1. (c, k) := Encaps(pk) denotes generation and encapsulation of symmetric key k
   under the recipient's public key pk.
1. k := Decaps(sk, c) denotes decapsulation of symmetric key k under the
   recipient's secret key sk.

To generate an aggregator's share, the client runs (c[i], k[i]) := Encaps(pk[i])
and sends c[i] to the aggregator. To compute its share, the aggregator would run
k[i] := Decaps(sk[i], c[i]) and compute its share as {x:i} = PRG(k[i], n).

[HPKE](https://datatracker.ietf.org/doc/draft-irtf-cfrg-hpke/) is a natural
candidate for instantiating the KEM. In "Export-Only" mode, HPKE provides an
efficient scheme with all the cryptographic agility we would ever need. And
although it's still an Internet-Draft, it has high quality implementations in a
variety of languages.

[[TODO: Specify how HPKE is used to implement Encaps() and Decaps().]]

### Pseudorandom number generation

A suitable PRG will have the following syntax. Fix a finite field K:

1. x := PRG(k, n) denotes generation of a vector of n elements of K.

This can be instantiated using a standard stream cipher, e.g.., ChaCha20 as
follows. Interpret k as the cipher key, and using a fixed nonce, generate l\*n
bytes of output, where l is the number of bytes needed to encode an element of
K, then map each chunk of l bytes to an element of K by interpreting the chunk
as an l-byte integer and reducing it modulo the prime modulus.

[[OPEN ISSUE: Mapping the output of PRG(.,.) to a vector over K induces a
small amount of bias on the output. How much bias is induced depends on the how
close the prime is to a power of 2. Should this be a criterion for selecting the
prime?]]

# Hits {#hits}

[TODO:]


# System design

[[OPEN ISSUE: This section seems like a catch-all for things not in other
sections. Perhaps there is a natural home for aggregator discovery, share
uploading, open issues, and system parameters?]]

## Aggregator discovery

[[OPEN ISSUE: writeme]]

## Share uploading

[[OPEN ISSUE: writeme]]

## Open questions and system parameters {#questions-and-params}

[[OPEN ISSUE: discuss batch size parameter and thresholds]]
[[OPEN ISSUE: discuss f^ leakage differences from [GB17]]]


# Operational Considerations

Prio has inherent constraints derived from the tradeoff between privacy
guarantees and computational complexity. These tradeoffs influence how
applications may choose to utilize services implementing the specification.

## Data resolution limitations

Privacy comes at the cost of computational complexity. While affine-aggregatable
encodings (AFEs) can compute many useful statistics, they require more bandwidth
and CPU cycles to account for finite-field arithmetic during input-validation.
The increased work from verifying inputs decreases the throughput of the system
or the inputs processed per unit time. Throughput is related to the verification
circuit's complexity and the available compute-time to each aggregator.

Applications that utilize proofs with a large number of multiplication gates or
a high frequency of inputs may need to limit inputs into the system to meet
bandwidth or compute constraints. Some methods of overcoming these limitations
include choosing a better representation for the data or introducing sampling
into the data collection methodology.

[[TODO: Discuss explicit key performance indicators, here or elsewhere.]]

## Aggregation utility and soft batch deadlines

A soft real-time system should produce a response within a deadline to
be useful. This constraint may be relevant when the value of an aggregate
decreases over time. A missed deadline can reduce an aggregate's utility
but not necessarily cause failure in the system.

An example of a soft real-time constraint is the expectation that input data can
be verified and aggregated in a period equal to data collection, given some
computational budget. Meeting these deadlines will require efficient
implementations of the input-validation protocol. Applications might batch
requests or utilize more efficient serialization to improve throughput.

Some applications may be constrained by the time that it takes to reach a
privacy threshold defined by a minimum number of input shares. One possible
solution is to increase the reporting period so more samples can be collected,
balanced against the urgency of responding to a soft deadline.

## Data integrity constraints

Data integrity concerns the accuracy and correctness of the outputs in the
system. The integrity of the output can be influenced by an incomplete round of
aggregation caused by network partitions, or by bad actors attempting to cause
inaccuracies in the aggregates. An example data integrity constraint is that
every share must be processed exactly once by all aggregators. Data integrity
constraints may be at odds with the threat model if meeting the constraints
requires replaying data.

Aggregator operators should expect to encounter invalid inputs during regular
operation due to misconfigured or malicious clients. Low volumes of errors are
tolerable; the input-verification protocol and AFEs are robust in the face of
malformed data. Aggregators may need to detect and mitigate statistically
significant floods of invalid or identical inputs that affect accuracy, e.g.,
denial of service (DoS) events.

Certain classes of errors do not exist in the input-validation protocol
considered in this document. For example, packet loss errors when clients make
requests directly to aggregators are not relevant when the leader proxies
requests and controls the schedule for signaling aggregation rounds.

# Security Considerations {#sec-considerations}

## Security overview {#security-requirements}

Prio assumes a powerful adversary with the ability to compromise an unbounded
number of clients. In doing so, the adversary can provide malicious (yet
truthful) inputs to the aggregation function. Prio also assumes that all but one
server operates honestly, where a dishonest server does not execute the protocol
faithfully as specified. The system also assumes that servers communicate over
secure and mutually authenticated channels. In practice, this can be done by TLS
or some other form of application-layer authentication.

In the presence of this adversary, Prio provides two important properties for
computing an aggergation function F:

1. Privacy. The aggregators and collector learn only the output of F computed
   over all client inputs, and nothing else.
1. Robustness. As long as the aggregators execute the input-validation protocol
   correctly, a malicious client can skew the output of F only by reporting
   false (untruthful) input. The output cannot be influenced in any other way.

There are several additional constraints that a Prio deployment must satisfy in
order to achieve these goals:

1. Minimum batch size. The aggregation batch size has an obvious impact on
   privacy. (A batch size of one hides nothing of the input.)
   {{questions-and-params}} discusses appropriate batch sizes and how they
   pertains to privacy in more detail.
2. Aggregation function choice. Some aggregation functions leak slightly more
   than the function output itself. {{questions-and-params}} discusses the
   leakage profiles of various aggregation functions in more detail.

### Threat model

In this section, we enumerate the actors participating in the Prio system and
enumerate their assets (secrets that are either inherently valuable or which
confer some capability that enables further attack on the system), the
capabilities that a malicious or compromised actor has, and potential
mitigations for attacks enabled by those capabilities.

This model assumes that all participants have previously agreed upon and
exchanged all shared parameters over some unspecified secure channel.

#### Client/user

##### Assets

1. Unshared inputs. Clients are the only actor that can ever see the original
   inputs.
1. Unencrypted input shares.

##### Capabilities

1. Individual users can reveal their own input and compromise their own privacy.
     * Since this does not affect the privacy of others in the system, it is
       outside the threat model.
1. Clients (that is, software which might be used by many users of the system)
can defeat privacy by leaking input outside of the Prio system.
     * In the current threat model, other participants have no insight into what
       clients do besides uploading input shares. Accordingly, such attacks are
       outside of the threat model.
1. Clients may affect the quality of aggregations by reporting false input.
     * Prio can only prove that submitted input is valid, not that it is true.
       False input can be mitigated orthogonally to the Prio protocol (e.g., by
       requiring that aggregations include a minimum number of contributions)
       and so these attacks are considered to be outside of the threat model.
1. Clients can send invalid encodings of input.

##### Mitigations

1. The input validation protocol executed by the aggregators prevents either
individual clients or coalitions of clients from compromising the robustness
property.

#### Aggregator

##### Assets

1. Unencrypted input shares.
1. Input share decryption keys.
1. Client identifying information.
1. Output shares.
1. Aggregator identity.

##### Capabilities

1. Aggregators may defeat the robustness of the system by emitting bogus output
   shares.
1. If clients reveal identifying information to aggregators (such as a trusted
   identity during client authentication), aggregators can learn which clients
   are contributing input.
     1. Aggregators may reveal that a particular client contributed input.
     1. Aggregators may attack robustness by selectively omitting inputs from
        certain clients.
          * For example, omitting submissions from a particular geographic
            region to falsely suggest that a particular localization is not
            being used.
1. Individual aggregators may compromise availability of the system by refusing
to emit output shares.
1. Input validity proof forging. Any aggregator can collude with a malicious
client to craft a proof share that will fool honest aggregators into accepting
invalid input.

##### Mitigations

1. The linear secret sharing scheme employed by the client ensures that privacy
   is preserved as long as at least one aggregator does not reveal its input
   shares.
1. If computed over a sufficient number of input shares, output shares reveal
   nothing about either the inputs or the participating clients.

#### Leader

The leader is also an aggregator, and so all the assets, capabilities and
mitigations available to aggregators also apply to the leader.

##### Capabilities

1. Input validity proof verification. The leader can forge proofs and collude
   with a malicious client to trick aggregators into aggregating invalid inputs.
     * This capability is no stronger than any aggregator's ability to forge
       validity proof shares in collusion with a malicious client.
1. Relaying messages between aggregators. The leader can compromise availability
   by dropping messages.
     * This capability is no stronger than any aggregator's ability to refuse to
       emit output shares.
1. Shrinking the anonymity set. The leader instructs aggregators to construct
   output parts and so could request aggregations over few inputs.

##### Mitigations

1. Aggregators enforce agreed upon minimum aggregation thresholds to prevent
   deanonymizing.

#### Collector

##### Capabilities

1. Advertising shared configuration parameters (e.g., minimum thresholds for
   aggregations, joint randomness, arithmetic circuits).
1. Collectors may trivially defeat availability by discarding output shares
   submitted by aggregators.

##### Mitigations

1. Aggregators should refuse shared parameters that are trivially insecure
   (i.e., aggregation threshold of 1 contribution).

#### Aggregator collusion

If all aggregators collude (e.g. by promiscuously sharing unencrypted input
shares), then none of the properties of the system hold. Accordingly, such
scenarios are outside of the threat model.

#### Attacker on the network

We assume the existence of attackers on the network links between participants.

##### Capabilities

1. Observation of network traffic. Attackers may observe messages exchanged
   between participants at the IP layer.
     1. The time of transmission of input shares by clients could reveal
        information about user activity.
          * For example, if a user opts into a new feature, and the client
            immediately reports this to aggregators, then just by observing
            network traffic, the attacker can infer what the user did.
     1. Observation of message size could allow the attacker to learn how much
        input is being submitted by a client.
          * For example, if the attacker observes an encrypted message of some
            size, they can infer the size of the plaintext, plus or minus the
            cipher block size. From this they may be able to infer which
            aggregations the user has opted into or out of.
1. Tampering with network traffic. Attackers may drop messages or inject new
   messages into communications between participants.

##### Mitigations

1. All messages exchanged between participants in the system should be
   encrypted.
1. All messages exchanged between aggregators, the collector and the leader
   should be mutually authenticated so that network attackers cannot impersonate
   participants.
1. Clients should be required to submit inputs at regular intervals so that the
   timing of individual messages does not reveal anything.
1. Clients should submit dummy inputs even for aggregations the user has not
   opted into.

[[OPEN ISSUE: The threat model for Prio --- as it's described in the original
paper and [BBG+19] --- considers **either** a malicious client (attacking
soundness) **or** a malicious subset of aggregators (attacking privacy). In
particular, soundness isn't guaranteed if any one of the aggregators is
malicious; in theory it may be possible for a malicious client and aggregator to
collude and break soundness. Is this a contingency we need to address? There are
techniques in [BBG+19] that account for this; we need to figure out if they're
practical.]]

### Future work and possible extensions

In this section we discuss attacks that are not considered in the above threat
model, and suggest mitigations that could be incorporated into implementations
of this protocol or future revisions of this specfication.

#### Client authentication

Attackers can impersonate Prio clients and submit large amounts of false input
in order to spoil aggregations. Deployments could require clients to
authenticate before they may contribute inputs. For example, by requiring
submissions to be signed with a key trusted by aggregators. However some
deployments may opt to accept the risk of false inputs to avoid having to figure
out how to distribute trusted identities to clients.

#### Client attestation

In the current threat model, servers participating in the protocol have no
insight into the activities of clients except that they have uploaded input into
a Prio aggregation, meaning that clients could covertly leak a user's data into
some other channel which compromises privacy. If we introduce the notion of a
trusted computing base which can attest to the properties or activities of a
client, then users and aggregators can be assured that their private data only
goes into Prio. For instance, clients could use the trusted computing base to
attest to software measurements over reproducible builds, or a trusted operating
system could attest to the client's network activity, allowing external
observers to be confident that no data is being exfiltrated.

#### Trusted anonymizing and authenticating proxy

While the input shares transmitted by clients to aggregators reveal nothing
about the original input, the aggregator can still learn auxiliary information
received messages (for instance, source IP or HTTP user agent), which can
identify participating clients or permit some attacks on robustness. This is
worse if client authentication used, since incoming messages would be bound to a
cryptographic identity. Deployments could include a trusted anonymizing proxy,
which would be responsible for receiving input shares from clients, stripping
any identifying information from them (including client authentication) and
forwarding them to aggregators. There should still be a confidential and
authenticated channel from the client to the aggregator to ensure that no actor
besides the aggregator may decrypt the input shares.

#### Multiple protocol runs

Prio is _robust_ against malicious clients, and _private_ against malicious
servers, but cannot provide robustness against malicious servers. Any aggregator
can simply emit bogus output shares and undetectably spoil aggregates. If enough
aggregators were available, this could be mitigated by running the protocol
multiple times with distinct subsets of aggregators chosen so that no aggregator
appears in all subsets and checking all the outputs against each other. If all
the protocol runs do not agree, then participants know that at least one
aggregator is defective, and it may be possible to identify the defector (i.e.,
if a majority of runs agree, and a single aggregator appears in every run that
disagrees). See
[#22](https://github.com/abetterinternet/prio-documents/issues/22) for
discussion.

### Security considerations

#### Infrastructure diversity

Prio deployments should ensure that aggregators do not have common dependencies
that would enable a single vendor to reassemble inputs. For example, if all
participating aggregators stored unencrypted input shares on the same cloud
object storage service, then that cloud vendor would be able to reassemble all
the input shares and defeat privacy.

## System requirements {#operational-requirements}

### Data types

# IANA Considerations

TODO

--- back
